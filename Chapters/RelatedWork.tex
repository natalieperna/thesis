\chapter{Related Work}
\label{cha:related_work}

In this chapter, we provide a survey of the literature and discuss some existing techniques for improving functional code that relate closely to our work.

\section{Common subexpression elimination}

Common subexpression elimination (CSE) is a compiler optimisation that reduces execution time by avoid repeated computations of the same expression.\cite{chitil1997} This very similar to our goal with case squashing. As anyone familiar with the nature of purely functional programming languages might realize, identification of common subexpressions is much simpler in a functional language thanks to the expectation of referential transparency.\cite{chitil1997} (As a reminder, referential transparency means that an expression always produces the same result regardless of the context in which it is evaluated.)

Appel first implemented CSE in the strict functional language ML's compiler in 1992.\cite{appel1992} Chitil first explored the implementation of CSE in a lazy functional language, Haskell, with his 1997 paper.\cite{chitil1997} The difficulty with implementing CSE in a lazy language is that, although common subexpressions are easy to identify, determining which common subexpressions will yield a benefit by being eliminated is more challenging. To avoid complex data flow analysis on functional code, Chitil developed some simple syntactic conditions for judging when CSE is beneficial in Haskell code.\cite{chitil1997} We omit these from our survey, as such heuristics are unnecessary for our optimisation. We instead focus on the relevant ``compilation by transformation'' approach used when implementing CSE in GHC.

The GHC compilation process consists of translating Haskell code into a second-order $\lambda$-calculus language called Core, at which point a series of optimising transformation are performed, and the backend transforms Core code into C.\cite{chitil1997} This process is very similar to the Agda compilation process, which translates Agda code into Treeless code, applies a series of optimising transformations, and finally generates Haskell code through the backend, as discussed in Section~\ref{sec:agda_compiler}.

The syntax of the Core intermediate language of Haskell is very similar to Treeless, with expressions consisting mainly of $\lambda$ abstractions, \lstinline{let} bindings, \lstinline{case} expressions, constructors, literals and function applications, much like Agda's Treeless syntax outlined in Figure~\ref{code:TTerm}.

CSE is implemented in GHC with a single recursive traversal of the Core program. For each expression, its subexpressions are first transformed, then it is determined whether the whole transformed expression has occurred already.\cite{chitil1997} An example of this is shown in Figure~\ref{code:cse_haskell}.

\begin{figure}[h]
Given the expression:

\lstinline{let x = 3 in let y = 2+3 in 2+3+4}

the first CSE on the subexpressions yields:

\lstinline{let x = 3 in let y = 2+x in y+4}

and then the recursive transormation produces:

\lstinline{let x = 3 in let y = 2+x in 2+x+4}

\caption{Common subexpression elimination transformation in Haskell.\cite{chitil1997}}
\label{code:cse_haskell}
\end{figure}

\section{Let-floating}
\label{sec:let_floating}

% TODO
\edcomm{WK}{3.2 Let-floating would profit from expansion and examples for every transformation.}

The 1996 paper by Simon Peyton Jones et al., ``Let-floating: moving bindings to give faster programs'', discusses the effects of a group of compiler optimisations for Haskell which move let bindings to reduce heap allocation and execution time.\cite{jones1996}

In this paper, three types of let-floating transformations are presented:
\begin{enumerate}
\item ``Floating inwards'' to move bindings as far inwards as possible,
\item ``The full laziness transformation'' which floats some bindings outside enclosing lambda abstractions, and
\item ``Local transformations'' which move bindings a several optimising ways.\cite{jones1996}
\end{enumerate}

\subsection*{Floating inwards}

Floating inwards is an straighforward optimisation that aims to move all let bindings as far inward in the expression tree as possible. This accomplishes three separate benefits:
\begin{itemize}
\item It increases the chance that a binding will not be met in program execution, if it is not needed on a particular branch.
\item It increases the chance that strictness analysis will be able to perform further optimisations.
\item It makes it possible for further redundant expressions to be eliminated.\cite{jones1996}
\end{itemize}

Consider as an example, the Haskell code:
\begin{lstlisting}
let x = case y of (a,b) -> a
in
case y of
  (p,q) -> x+p
\end{lstlisting}

and its optimised version with let-bindings floated inward:
\begin{lstlisting}
case y of
  (p,q) -> let x = case y of (a,b) -> a
           in x+p
\end{lstlisting}

These two Haskell expressions are semantically-equivalent, but the second has potential to become more efficient than the first because later optimisations will be able to idenfity the opportunity to remove the redundant inner case expression which scrutinises the same variable as the outer case expression.\cite{jones1996} Though it wasn't clear in the first expression, because the case expressions weren't nested, the second expression can now benefit from a GHC optimisation much like our ``case squashing'' optimisation.

\subsection*{Full laziness}

While the above transformation attempts to push bindings inwards, the full laziness transformation does the reverse, floating bindings outwards. By floating some bindings out of lambda abstractions, we can avoid re-computing the same expression on repeated recursive calls to the same function.\cite{jones1996}

The benefit from this increased sharing outweighs the detriment of increasing the let scope in most cases where:
\begin{itemize}
\item the expression being bound requires a non-negligible amount of computational work to evaluate; and
\item the lambda abstraction it is used in is called more than once.\cite{jones1996}
\end{itemize}

Consider as an example, the Haskell code\cite{jones1996}:
\begin{lstlisting}
f = \xs ->
  let g = \y -> let n = length xs
                in ...g...n...
  in ...g...
\end{lstlisting}

and its optimised version with let-bindings floated outward:
\begin{lstlisting}
f = \xs ->
  let n = length xs
  in let g = \y -> ...g...n...
     in ...g...
\end{lstlisting}

In order to maximise the number of opportunities for this type of let-floating, it may be necessary to create dummy let bindings for free subexpressions in the lambda abstraction, so that they can be floated out as well.\cite{jones1996}

\subsection*{Local transformations}

The local transformations consist of a series of three small rewrite rules as follows:

\begin{enumerate}
\item \lstinline[style=math]{(let $v$=$e$ in $b$) $a$ $\to$ (let $v$=$e$ in $b$ $a$)}

Moving the let outside the application cannot have a negative effect, but it can have a positive effect by creating opportunities for other optimisations.\cite{jones1996}

\item \lstinline[style=math]{case (let $v$=$e$ in $b$) of $alts$ $\to$ let $v$=$e$ in case $b$ of $alts$}

Likewise for moving the let outside a case expression, it won't have a negative effect, but could have a positive effect.\cite{jones1996}

\item \lstinline[style=math]{let $x$ = let  $v$=$e$ in $b$ in $c$ $\to$ let $v$=$e$ in let $x$ = $b$ in $c$}

Moving a let binding from the right-hand side of another let binding to outside it can have several advantages including potentially reducing the need for some heap allocation when the final form of the second binding becomes more clear.\cite{jones1996}
\end{enumerate}

Similar methods to these let-floating transformations are used in our patterned let-floating across function calls, with the same goal of increasing sharing and decreasing re-evaluation of the same expressions.

\section{Alternate method of case squashing}
\label{sub:alternate_case_squash}

Following development of \texttt{-{}-squash-cases}, an optimisation was added to the Agda compiler's Simplify stage which accomplishes the same goals as \texttt{-{}-squash-cases} in a slightly different way. We examine here that method of removing repeated case expressions.

Immediately following the conversion of compiled clauses to treeless syntax in the Agda compiler, a series of optimising transformations are applied before the treeless expression is returned. One such step is the ``simplify'' group of transformations, which modify a \lstinline{TTerm} in a variety of optimising ways.

As the expression is traversed, \lstinline{simplify} is recursively called on each \lstinline{TTerm} term, and \lstinline{simpAlt} is called on each \lstinline{TAlt} alternative. Given some expression casing on de Bruijn index $x$, for each alternative of the pattern \lstinline{TACon name arity body}, the scrutinized variable index in the body, $x + arity$, is looked up in the variable environment. If the variable has already been bound, and therefore has a different de Bruijn index, $y$, a rewrite rule is added to the constructor. The rewrite rule indicates that every instance of \lstinline{TApp (TCon name) (TVar i | i <- [arity-1,arity-2..0])} in the alternative's body should be replaced with a \lstinline{TVar y}.

The rewrite rule is encoded as part of the wrapper \lstinline{Reader} environment that is carried along with the \lstinline{TTerm} throughout simplification, and is evaluated later by applying substitutions. It is at this point that all necessary de Bruijn index shifting is managed.

An abridged version of \texttt{Treeless/Simplify.hs} showing the primary functions involved in this optimisation in the updated Agda compiler is available in Appendix~\ref{app:simplify}.
